{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation d’un PMC pour la classification de Chiffres Manuscrits\n",
    "# Notion d'optimisation d'une architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeux d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix de l'entrée du classifieur\n",
    "Ici, on choisit le codage binaire (i.e. représenté par des -1 et des 1) que l'on va mettre en entrée du perceptron multicouches. Chaque représentation du chiffre manuscrit correspond à un vecteur.  \n",
    "On peut utiliser le codage brut chiffre manuscrit avec son codage d'un 1 pour les pixels sur lesquels le stylo est passé et -1 là où il n'est pas passé. (L'imagette est mise sous forme de vecteur en mettant les lignes les unes à la suite des autres.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt(\"x.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi l'une des multiples variantes de codages associées à la représentation du nombre proposées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = np.loadtxt(\"hx.txt\")\n",
    "hx_hy = np.loadtxt(\"hx_hy.txt\")\n",
    "pb_ph = np.loadtxt(\"pb_ph.txt\")\n",
    "pg_pd = np.loadtxt(\"pg_pd.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi choisir d'utiliser une combinaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx_hy_pb_ph = np.loadtxt(\"hx_hy_pb_ph.txt\")\n",
    "hx_hy_pg_pd = np.loadtxt(\"hx_hy_pg_pd.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi, toutes ces possibilités, on en garde une comme entrée du réseau `X`.  \n",
    "Pour la suite, on supprime les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.T\n",
    "del x, hx, hx_hy, pb_ph, pg_pd, hx_hy_pb_ph, hx_hy_pg_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui est de la sortie, il s'agit d'un vecteur codant la classe  associée au chiffre manuscrit.  \n",
    "La sortie désirée (`t` pour target) est, comme les entrées, un vecteur binaire (i.e. représenté par des -1 et des 1) de 10 colonnes (une pour chaque classe). Tous les éléments sont à -1 à l'exception de l'élément dont l'indice correspondant à la classe.   \n",
    "Ainsi une représentation manuscrite des nombres 0, 3 et 9 auront tous leurs éléments à -1 à l'exception de leur, respectivement, premier, quatrième et dixième élément qui lui vaudra 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.loadtxt(\"t.txt\").T\n",
    "t_label_num = np.where(t==1)[1]\n",
    "class_label = ['zero','un','deux','trois','quatre','cinq','six','sept','huit','neuf']\n",
    "t_label_str = [ class_label[i] for i in t_label_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour la suite on à décider de remplacer les -1 par des 0.**  \n",
    "Ainsi pour chaque chiffre on a neuf 0 et un 1. \n",
    "On a donc les probabilités d'appartenance aux classes de chiffres comme sorties désirées.  \n",
    "La sortie fournit par le PMC correspondra ainsi à la probabilité estimée par le réseau.  \n",
    "(Attention, un PMC n'a pas par défaut de contrainte pour respecter les axiomes des probabilités.  \n",
    "Il pourra fournir des sorties inférieures à 0, supérieures à 1 ainsi qu'une somme des dix sorties elle aussi inférieure à 0 ou supérieure à 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[np.where(t==-1)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous reste à réaliser nos ensembles d'apprentissage.  \n",
    "On a $48 \\times 10$ chiffres manuscrits qui correspondent à $48$ séries de $10$ chiffres ordonnés allant de $0$ à $9$.  \n",
    "On va grossièrement prendre les premières séries pour l'apprentissage et les dernières pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 28*10\n",
    "# rescale the data, use the traditional train/test split\n",
    "X_appVal, X_test = X[:200,:], X[200:,:]\n",
    "t_appVal, t_test = t[:200,:], t[200:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000000\n",
      "Test set score: 0.764286\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=4000,\n",
    "                    alpha=1e-4,\n",
    "                    validation_fraction=.7,\n",
    "                    #solver='sgd', \n",
    "                    tol=1e-6, \n",
    "                    solver='lbfgs', learning_rate = 'adaptive',\n",
    "                    random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_appVal, t_appVal)\n",
    "print(\"Training set score: %f\" % mlp.score(X_appVal, t_appVal))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, dans un cadre contraint, on va chercher à déterminer une architecture optimale.\n",
    "Dans la suite, on s'intéressara à trois types d’architectures.\n",
    "Pour cette architecture optimale, avec un jeu de poids associés, on calculera les performances en apprentissage validation et test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation de la première architecure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on s'intéresse à un réseau linéaire entièrement connecté sans couche cachée.\n",
    "On effectue donc une régression multilinéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.100000\n",
      "Test set score: 0.028571\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1,), max_iter=4000,\n",
    "                    alpha=1e-4,\n",
    "                    activation='identity',\n",
    "                    validation_fraction=.7,\n",
    "                    #solver='sgd', \n",
    "                    tol=1e-6, \n",
    "                    solver='lbfgs', learning_rate = 'adaptive',\n",
    "                    random_state=1)\n",
    "\n",
    "mlp.fit(X_appVal, t_appVal)\n",
    "print(\"Training set score: %f\" % mlp.score(X_appVal, t_appVal))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation de la seconde architecure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on s'intéresse à un réseau Sigmoïdal entièrement connecté sans couche cachée.\n",
    "On effectue donc une transformation non linéaire à la réponse fournie par une régression multilinéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000000\n",
      "Test set score: 0.664286\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=4000,\n",
    "                    alpha=1e-4,\n",
    "                    activation='identity',\n",
    "                    validation_fraction=.7,\n",
    "                    #solver='sgd', \n",
    "                    tol=1e-6, \n",
    "                    solver='lbfgs', learning_rate = 'adaptive',\n",
    "                    random_state=1)\n",
    "\n",
    "mlp.fit(X_appVal, t_appVal)\n",
    "print(\"Training set score: %f\" % mlp.score(X_appVal, t_appVal))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation de la troisième architecure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on s'intéresse à un réseau entièrement connecté à une couche caché.\n",
    "Cela est éqiuvalent à utiliser une combinaison linéaires des réseaux sigmaodïdaux de la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000000\n",
      "Test set score: 0.771429\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=4000,\n",
    "                    alpha=1e-4,\n",
    "                    activation='tanh',\n",
    "                    validation_fraction=.7,\n",
    "                    #solver='sgd', \n",
    "                    tol=1e-6, \n",
    "                    solver='lbfgs', learning_rate = 'adaptive',\n",
    "                    random_state=1)\n",
    "\n",
    "mlp.fit(X_appVal, t_appVal)\n",
    "print(\"Training set score: %f\" % mlp.score(X_appVal, t_appVal))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, t_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
